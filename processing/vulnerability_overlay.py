"""
HEAT — Vulnerability Overlay System (Shift 7)

Loads static Census ACS data for the 17 target ZIPs, computes a
composite vulnerability index per ZIP, and exports a GeoJSON
choropleth layer for Leaflet rendering.

Pipeline integration:
    from vulnerability_overlay import run_vulnerability_overlay
    run_vulnerability_overlay()   # writes build/data/vulnerability.geojson

No runtime API dependency — ACS data is bundled in
build/data/census_acs.json.
"""
from __future__ import annotations

import json
import logging
import math
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Optional

logger = logging.getLogger(__name__)

# ---------------------------------------------------------------------------
# Paths
# ---------------------------------------------------------------------------
BUILD_DIR = Path(__file__).parent.parent / "build" / "data"
ACS_PATH = BUILD_DIR / "census_acs.json"
OUTPUT_PATH = BUILD_DIR / "vulnerability.geojson"

# ---------------------------------------------------------------------------
# Import project constants
# ---------------------------------------------------------------------------
try:
    from config import ZIP_CENTROIDS
except ImportError:
    try:
        from processing.config import ZIP_CENTROIDS
    except ImportError:
        ZIP_CENTROIDS = {
            "07060": (40.6137, -74.4154),
            "07062": (40.6280, -74.4050),
            "07063": (40.5980, -74.4280),
            "08817": (40.5300, -74.3930),
            "08820": (40.5800, -74.3600),
            "08837": (40.5290, -74.3370),
            "07030": (40.7350, -74.0303),
            "08608": (40.2206, -74.7597),
            "08609": (40.2250, -74.7520),
            "08610": (40.2180, -74.7650),
            "08611": (40.2280, -74.7450),
            "08618": (40.2120, -74.7750),
            "08619": (40.2340, -74.7350),
            "08901": (40.4862, -74.4518),
            "08902": (40.4950, -74.4400),
            "08903": (40.4750, -74.4600),
            "08906": (40.4950, -74.4700),
        }

# ---------------------------------------------------------------------------
# Vulnerability index computation
# ---------------------------------------------------------------------------

# Weights for each ACS indicator (sum = 1.0).
# Higher weight → larger contribution to vulnerability.
INDICATOR_WEIGHTS = {
    "median_income":            -0.20,  # negative: lower income → higher vuln
    "linguistic_isolation_pct":  0.25,
    "foreign_born_pct":          0.20,
    "renter_pct":                0.15,
    "no_vehicle_pct":            0.20,
}


def load_acs_data(acs_path: Path | None = None) -> dict:
    """Load static ACS JSON and return the ``zips`` dict."""
    acs_path = acs_path or ACS_PATH
    if not acs_path.exists():
        raise FileNotFoundError(f"ACS data file not found: {acs_path}")
    with open(acs_path, encoding="utf-8") as f:
        data = json.load(f)
    return data.get("zips", data)


def _min_max_normalize(values: list[float]) -> list[float]:
    """Normalize a list of floats to [0, 1] via min-max scaling."""
    mn, mx = min(values), max(values)
    rng = mx - mn
    if rng == 0:
        return [0.5] * len(values)
    return [(v - mn) / rng for v in values]


def compute_vulnerability_index(
    acs_data: dict,
    weights: dict[str, float] | None = None,
) -> dict[str, dict]:
    """
    Compute a 0–100 composite vulnerability index for each ZIP.

    Steps:
      1. For each indicator, min-max normalize across all ZIPs.
      2. For negative-weight indicators (e.g. income), invert the
         normalized value (1 - n) so that *lower* raw values yield
         *higher* vulnerability.
      3. Weighted sum → composite score.
      4. Re-scale composite to 0–100.

    Returns ``{ zip: { index, category, indicators: { ... } } }``.
    """
    weights = weights or INDICATOR_WEIGHTS
    zips = sorted(acs_data.keys())

    # Collect raw values per indicator
    raw: dict[str, list[float]] = {k: [] for k in weights}
    for z in zips:
        for ind in weights:
            raw[ind].append(float(acs_data[z].get(ind, 0)))

    # Normalize
    normed: dict[str, list[float]] = {}
    for ind, vals in raw.items():
        normed[ind] = _min_max_normalize(vals)

    # Compute weighted composite
    composites: list[float] = []
    for i, z in enumerate(zips):
        score = 0.0
        for ind, w in weights.items():
            n = normed[ind][i]
            if w < 0:
                n = 1 - n   # invert for negative-weight indicators
                w = abs(w)
            score += n * w
        composites.append(score)

    # Re-scale to 0–100
    c_norm = _min_max_normalize(composites)

    results: dict[str, dict] = {}
    for i, z in enumerate(zips):
        idx = round(c_norm[i] * 100, 1)
        cat = (
            "very_high" if idx >= 80 else
            "high" if idx >= 60 else
            "moderate" if idx >= 40 else
            "low" if idx >= 20 else
            "very_low"
        )
        results[z] = {
            "index": idx,
            "category": cat,
            "name": acs_data[z].get("name", z),
            "indicators": {ind: acs_data[z].get(ind) for ind in weights},
        }

    return results


# ---------------------------------------------------------------------------
# GeoJSON export — approximate ZIP polygon (circle)
# ---------------------------------------------------------------------------

def _zip_polygon(lat: float, lon: float, radius_km: float = 1.5, n_points: int = 32) -> list:
    """Approximate a circular polygon around (lat, lon)."""
    coords = []
    for i in range(n_points + 1):
        angle = 2 * math.pi * (i % n_points) / n_points
        dlat = (radius_km / 111.32) * math.cos(angle)
        dlon = (radius_km / (111.32 * math.cos(math.radians(lat)))) * math.sin(angle)
        coords.append([round(lon + dlon, 6), round(lat + dlat, 6)])
    return [coords]


def export_vulnerability_geojson(
    vuln_index: dict[str, dict],
    centroids: dict[str, tuple[float, float]] | None = None,
    output_path: Path | None = None,
) -> Path:
    """
    Export vulnerability index as a GeoJSON FeatureCollection
    of Polygon features (choropleth-ready).
    """
    centroids = centroids or ZIP_CENTROIDS
    output_path = Path(output_path or OUTPUT_PATH)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    features: list[dict] = []
    for z, data in vuln_index.items():
        c = centroids.get(z)
        if not c:
            continue
        features.append({
            "type": "Feature",
            "geometry": {
                "type": "Polygon",
                "coordinates": _zip_polygon(c[0], c[1]),
            },
            "properties": {
                "zip": z,
                "name": data.get("name", z),
                "vulnerability_index": data["index"],
                "category": data["category"],
                **data.get("indicators", {}),
            },
        })

    collection = {
        "type": "FeatureCollection",
        "features": features,
        "metadata": {
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "description": "HEAT vulnerability overlay (Census ACS composite index)",
            "index_range": "0–100 (higher = more vulnerable)",
            "categories": ["very_low", "low", "moderate", "high", "very_high"],
        },
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(collection, f, ensure_ascii=False, indent=2, default=str)

    logger.info("Exported vulnerability overlay → %s (%d ZIPs)", output_path, len(features))
    return output_path


# ===================================================================
# Top-level entry point
# ===================================================================

def run_vulnerability_overlay() -> dict:
    """
    End-to-end vulnerability overlay generation.

    Returns summary dict.
    """
    logger.info("=" * 50)
    logger.info("HEAT Vulnerability Overlay")
    logger.info("=" * 50)

    acs_data = load_acs_data()
    logger.info("Loaded ACS data for %d ZIPs", len(acs_data))

    vuln = compute_vulnerability_index(acs_data)

    # Log summary
    for z, v in sorted(vuln.items(), key=lambda x: -x[1]["index"]):
        logger.info("  %s %-25s  index=%.1f  (%s)",
                     z, v["name"], v["index"], v["category"])

    out_path = export_vulnerability_geojson(vuln)

    return {
        "zips": len(vuln),
        "output": str(out_path),
        "highest": max(vuln.items(), key=lambda x: x[1]["index"])[0] if vuln else None,
        "lowest": min(vuln.items(), key=lambda x: x[1]["index"])[0] if vuln else None,
    }


# ===================================================================
# CLI
# ===================================================================
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
    result = run_vulnerability_overlay()
    print(json.dumps(result, indent=2, default=str))
