name: HEAT Pipeline - Scheduled Scrape

on:
  schedule:
    # Run every 6 hours
    - cron: '0 */6 * * *'
  workflow_dispatch:
    inputs:
      full_run:
        description: 'Run full pipeline (including social media)'
        required: false
        default: true
        type: boolean

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version-file: '.python-version'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          # Install numpy first so thinc's C-extension compiles/links against it.
          # Force-reinstall numpy and thinc to avoid stale cached binaries.
          pip install --force-reinstall "numpy~=2.4.0"
          pip install --force-reinstall "thinc>=8.2.2,<8.3.0"
          pip install -r requirements.txt

      - name: Download spaCy model
        run: python -m spacy download en_core_web_sm

      - name: Cache HuggingFace models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: hf-models-${{ hashFiles('requirements.txt') }}
          restore-keys: hf-models-

      - name: Run pipeline
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          TWITTER_BEARER_TOKEN: ${{ secrets.TWITTER_BEARER_TOKEN }}
          FACEBOOK_ACCESS_TOKEN: ${{ secrets.FACEBOOK_ACCESS_TOKEN }}
        run: |
          python run_pipeline.py --full

      - name: Check for data changes
        id: check_changes
        run: |
          git diff --quiet build/data/ || echo "changed=true" >> $GITHUB_OUTPUT

      - name: Commit updated data
        if: steps.check_changes.outputs.changed == 'true'
        run: |
          git config user.name "HEAT Pipeline Bot"
          git config user.email "heat-bot@users.noreply.github.com"
          git add build/data/
          git commit -m "Auto-update: pipeline data $(date -u +'%Y-%m-%d %H:%M UTC')"
          git push

      - name: Deploy to S3 (if configured)
        if: steps.check_changes.outputs.changed == 'true' && env.AWS_ACCESS_KEY_ID != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION || 'us-east-1' }}
          S3_BUCKET: ${{ secrets.S3_BUCKET }}
        run: |
          aws s3 sync build/ s3://$S3_BUCKET/ --delete --exclude ".git/*"

      - name: Notify on failure
        if: failure()
        run: |
          echo "Pipeline failed at $(date -u). Check logs for details."
